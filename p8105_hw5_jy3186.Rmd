---
title: "p8105_hw5_jy3186"
author: "Jiayi Yang"
date: "2022-11-10"
output: github_document
---

```{r setup, include=FALSE}
library(readxl)
library(tidyverse)
```

## Problem 2
Import and tidy the dataset
```{r, message = FALSE}
homicide_df = 
  read_csv(url("https://github.com/washingtonpost/data-homicides/blob/master/homicide-data.csv?raw=true"))
```

Create a city_state variable (e.g. “Baltimore, MD”) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).

```{r}
homicide_new =
homicide_df %>% 
  mutate(city_state = str_c(city, state, sep = ", ")) %>% 
  group_by(city_state)

homicide_count = 
  homicide_new %>% 
  group_by(city_state) %>% 
  summarize(homicide_total = n())

homicide_unsolved =
  homicide_new %>% 
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) %>% 
  group_by(city_state) %>% 
  summarize(unsolved_total = n())

homicide_table = 
  merge(homicide_count, homicide_unsolved, by = "city_state")

knitr::kable(homicide_table)
```

use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object,
apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe
```{r}
prop.test(
  x = homicide_unsolved %>% 
    filter(city_state == "Baltimore, MD") %>% 
    pull(unsolved_total),
  n = homicide_count %>% 
    filter(city_state == "Baltimore, MD") %>% 
    pull(homicide_total)
  )%>% 
    broom::tidy()

```

Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Using mapping.
```{r}
homicide_map = 
  homicide_table %>% 
  mutate(
    prop = map2(.x = unsolved_total, .y = homicide_total, ~prop.test(x=.x, n =.y)),
    clean = map(.x = prop, ~broom::tidy(.x)) 
  ) %>% 
  unnest(clean) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

Create a plot that shows the estimates and CIs for each city, check out geom_errorbar for a way to add error bars
```{r}
homicide_plot = 
  homicide_map %>% 
  mutate(
    city_state =  fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) + geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.6, hjust = 1), legend.position = "bottom")

homicide_plot
```

## Problem 3
First set the following design elements:
Fix n=30
Fix σ=5
Set μ=0.  write a t-test function, with broom::tidy to obtain estimate and p-value
```{r}
set.seed(0)
n =30
mu =0
sigma =5
x = rnorm(n, mean = mu, sd = sigma)
t.test(x, mu = mu, conf.level=0.95)
sim_test = function(n, mu = 0, sigma = 5){
    x = rnorm(n, mean = mu, sd = sigma)
    t_test = t.test(x, conf.int = 0.95) %>% broom::tidy()
    t_test
}

```
Generate 5000 datasets from the model
```{r}
sim_results_df = 
  expand_grid(
    sample_size = 30,
    iter = 1:5000
  ) %>% 
  mutate(
    estimate_df = map(sample_size, sim_test)
  ) %>% 
  unnest(estimate_df)
```
and repeat with mu = 1,2,3,4,5,6
```{r}
sim_results = 
tibble(
  mu = c(1,2,3,4,5,6)
) %>% 
  mutate(
    output_list = map(.x = mu, ~rerun(5000, sim_test(n, mu = .x, sigma))),
    estimate_df = map(output_list, bind_rows)
  ) %>% 
  select(-output_list) %>% 
  unnest(estimate_df)


```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.
```{r}
sim_results %>% 
  filter(p.value < 0.05) %>% 
  group_by(mu) %>% 
  summarize(
    reject = n()
  ) %>% 
  mutate(
    proportion = reject/5000
  ) %>% 
  ggplot(aes(x = mu, y = proportion))+geom_line()+
  geom_point() + scale_x_continuous(limits = c(1,6), breaks = seq(1,6,1)) +
    labs(
    title = "Association between power of test and true value of μ",
    x = "mean",
    y = "proportion of time null was rejected"
  )
```

As the mean of sample gets larger, the power of the test gets larger